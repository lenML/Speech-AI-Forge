import html
import os
import re

import emojiswitch
import ftfy
from pywrapfst import FstOpError

from modules.core.models import zoo
from modules.core.tn.TNPipeline import GuessLang, TNPipeline
from modules.repos_static.zh_normalization.text_normlization import TextNormalizer
from modules.utils.HomophonesReplacer import HomophonesReplacer
from modules.utils.html import remove_html_tags as _remove_html_tags
from modules.utils.markdown import markdown_to_text

DISABLE_UNK_TOKEN_CHECK = False

ChatTtsTN = TNPipeline()
ChatTtsTN.freeze_strs = [
    "[Sasr]",
    "[Pasr]",
    "[Easr]",
    "[Stts]",
    "[Ptts]",
    "[Etts]",
    "[Sbreak]",
    "[Pbreak]",
    "[Ebreak]",
    "[uv_break]",
    "[v_break]",
    "[lbreak]",
    "[llbreak]",
    "[undefine]",
    "[laugh]",
    "[spk_emb]",
    "[empty_spk]",
    "[music]",
    "[pure]",
    "[break_0]",
    "[break_1]",
    "[break_2]",
    "[break_3]",
    "[break_4]",
    "[break_5]",
    "[break_6]",
    "[break_7]",
    "[laugh_0]",
    "[laugh_1]",
    "[laugh_2]",
    "[oral_0]",
    "[oral_1]",
    "[oral_2]",
    "[oral_3]",
    "[oral_4]",
    "[oral_5]",
    "[oral_6]",
    "[oral_7]",
    "[oral_8]",
    "[oral_9]",
    "[speed_0]",
    "[speed_1]",
    "[speed_2]",
    "[speed_3]",
    "[speed_4]",
    "[speed_5]",
    "[speed_6]",
    "[speed_7]",
    "[speed_8]",
    "[speed_9]",
]

# ------- UTILS ---------


def is_markdown(text):
    markdown_patterns = [
        r"(^|\s)#[^#]",  # æ ‡é¢˜
        r"\*\*.*?\*\*",  # åŠ ç²—
        r"\*.*?\*",  # æ–œä½“
        r"!\[.*?\]\(.*?\)",  # å›¾ç‰‡
        r"\[.*?\]\(.*?\)",  # é“¾æ¥
        r"`[^`]+`",  # è¡Œå†…ä»£ç 
        r"```[\s\S]*?```",  # ä»£ç å—
        r"(^|\s)\* ",  # æ— åºåˆ—è¡¨
        r"(^|\s)\d+\. ",  # æœ‰åºåˆ—è¡¨
        r"(^|\s)> ",  # å¼•ç”¨
        r"(^|\s)---",  # åˆ†éš”çº¿
    ]

    for pattern in markdown_patterns:
        if re.search(pattern, text, re.MULTILINE):
            return True

    return False


character_map = {
    "ï¼š": "ï¼Œ",
    "ï¼›": "ï¼Œ",
    "ï¼": "ã€‚",
    "ï¼ˆ": "ï¼Œ",
    "ï¼‰": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€‘": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€Œ": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€Š": "ï¼Œ",
    "ã€‹": "ï¼Œ",
    "ï¼": "ï¼Œ",
    "â€˜": " ",
    "â€œ": " ",
    "â€™": " ",
    "â€": " ",
    '"': " ",
    "'": " ",
    ":": ",",
    ";": ",",
    "!": ".",
    "(": ",",
    ")": ",",
    "[": ",",
    "]": ",",
    ">": ",",
    "<": ",",
    "-": ",",
    "~": " ",
    "ï½": " ",
    "/": " ",
    "Â·": " ",
}

# -----------------------


@ChatTtsTN.block()
def html_unescape(text: str, guess_lang: GuessLang):
    text = html.unescape(text)
    text = html.unescape(text)
    return text


@ChatTtsTN.block()
def fix_text(text: str, guess_lang: GuessLang):
    return ftfy.fix_text(text=text)


@ChatTtsTN.block()
def apply_markdown_to_text(text: str, guess_lang: GuessLang):
    if is_markdown(text):
        text = markdown_to_text(text)
    return text


@ChatTtsTN.block()
def remove_html_tags(text: str, guess_lang: GuessLang):
    return _remove_html_tags(text)


# å°† "xxx" => \nxxx\n
# å°† 'xxx' => \nxxx\n
@ChatTtsTN.block()
def replace_quotes(text: str, guess_lang: GuessLang):
    repl = r"\n\1\n"
    patterns = [
        ['"', '"'],
        ["'", "'"],
        ["â€œ", "â€"],
        ["â€˜", "â€™"],
    ]
    for p in patterns:
        text = re.sub(rf"({p[0]}[^{p[0]}{p[1]}]+?{p[1]})", repl, text)
    return text


# ---- main normalize ----


@ChatTtsTN.block(name="tx_zh", enabled=True)
def tx_normalize(text: str, guss_lang: GuessLang):
    if guss_lang.zh_or_en != "zh":
        return text
    # NOTE: è¿™ä¸ªæ˜¯é­”æ”¹è¿‡çš„ TextNormalizer æ¥è‡ª PaddlePaddle
    tx = TextNormalizer()
    # NOTE: ä¸ºä»€ä¹ˆè¦åˆ†è¡Œï¼Ÿå› ä¸ºæˆ‘ä»¬éœ€è¦ä¿ç•™ "\n" ä½œä¸º chunker çš„åˆ†å‰²ä¿¡å·
    lines = [line for line in text.split("\n") if line.strip() != ""]
    texts: list[str] = []
    for line in lines:
        ts = tx.normalize(line)
        texts.append("".join(ts))
    return "\n".join(texts)


@ChatTtsTN.block(name="wetext_en", enabled=True)
def wetext_normalize(text: str, guss_lang: GuessLang):
    # NOTE: wetext ä¾èµ– pynini æ— æ³•åœ¨ windows ä¸Šå®‰è£…ï¼Œæ‰€ä»¥è¿™é‡Œåªåœ¨ linux ä¸Šå¯ç”¨
    if os.name == "nt":
        return text
    if guss_lang.zh_or_en == "en":
        from tn.english.normalizer import Normalizer as EnNormalizer

        en_tn_model = EnNormalizer(overwrite_cache=False)
        try:
            return en_tn_model.normalize(text)
        except FstOpError:
            # NOTE: ä¸å¤ªç†è§£ä¸ºä»€ä¹ˆ tn éƒ½èƒ½å‡ºé”™...
            pass
    return text


# ---- end main normalize ----


@ChatTtsTN.block()
def apply_character_map(text: str, guess_lang: GuessLang):
    translation_table = str.maketrans(character_map)
    return text.translate(translation_table)


@ChatTtsTN.block()
def apply_emoji_map(text: str, guess_lang: GuessLang):
    return emojiswitch.demojize(text, delimiters=("", ""), lang=guess_lang.zh_or_en)


@ChatTtsTN.block()
def insert_spaces_between_uppercase(text: str, guess_lang: GuessLang):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åœ¨æ¯ä¸ªç›¸é‚»çš„å¤§å†™å­—æ¯ä¹‹é—´æ’å…¥ç©ºæ ¼
    return re.sub(
        r"(?<=[A-Z])(?=[A-Z])|(?<=[a-z])(?=[A-Z])|(?<=[\u4e00-\u9fa5])(?=[A-Z])|(?<=[A-Z])(?=[\u4e00-\u9fa5])",
        " ",
        text,
    )


@ChatTtsTN.block()
def replace_unk_tokens(text: str, guess_lang: GuessLang):
    """
    æŠŠä¸åœ¨å­—å…¸é‡Œçš„å­—ç¬¦æ›¿æ¢ä¸º " , "

    FIXME: æ€»æ„Ÿè§‰ä¸å¤ªå¥½...ä½†æ˜¯æ²¡æœ‰é‡åˆ°é—®é¢˜çš„è¯æš‚æ—¶ç•™ç€...
    """
    if DISABLE_UNK_TOKEN_CHECK:
        return text
    chat_tts = zoo.ChatTTS.load_chat_tts()
    if "tokenizer" not in chat_tts.pretrain_models:
        # è¿™ä¸ªåœ°æ–¹åªæœ‰åœ¨ huggingface spaces ä¸­æ‰ä¼šè§¦å‘
        # å› ä¸º hugggingface è‡ªåŠ¨å¤„ç†æ¨¡å‹å¸è½½åŠ è½½ï¼Œæ‰€ä»¥å¦‚æœæ‹¿ä¸åˆ°å°±ç®—äº†...
        return text
    tokenizer = zoo.ChatTTS.get_tokenizer()
    vocab = tokenizer.get_vocab()
    vocab_set = set(vocab.keys())
    # æ·»åŠ æ‰€æœ‰è‹±è¯­å­—ç¬¦
    vocab_set.update(set("abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"))
    vocab_set.update(set(" \n\r\t"))
    replaced_chars = [char if char in vocab_set else " , " for char in text]
    output_text = "".join(replaced_chars)
    return output_text


homo_replacer = HomophonesReplacer(
    map_file_path="./modules/ChatTTS/ChatTTS/res/homophones_map.json"
)


@ChatTtsTN.block()
def replace_homophones(text: str, guess_lang: GuessLang):
    if guess_lang.zh_or_en == "zh":
        text = homo_replacer.replace(text)
    return text


if __name__ == "__main__":
    from modules.devices import devices

    DISABLE_UNK_TOKEN_CHECK = True

    devices.reset_device()
    test_cases = [
        "ChatTTSæ˜¯ä¸“é—¨ä¸ºå¯¹è¯åœºæ™¯è®¾è®¡çš„æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ï¼Œä¾‹å¦‚LLMåŠ©æ‰‹å¯¹è¯ä»»åŠ¡ã€‚å®ƒæ”¯æŒè‹±æ–‡å’Œä¸­æ–‡ä¸¤ç§è¯­è¨€ã€‚æœ€å¤§çš„æ¨¡å‹ä½¿ç”¨äº†10ä¸‡å°æ—¶ä»¥ä¸Šçš„ä¸­è‹±æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒã€‚åœ¨HuggingFaceä¸­å¼€æºçš„ç‰ˆæœ¬ä¸º4ä¸‡å°æ—¶è®­ç»ƒä¸”æœªSFTçš„ç‰ˆæœ¬.",
        " [oral_9] [laugh_0] [break_0] ç”µ [speed_0] å½± [speed_0] ä¸­ æ¢æœä¼Ÿ [speed_9] æ‰®æ¼”çš„é™ˆæ°¸ä»çš„ç¼–å·27149",
        " æ˜å¤©æœ‰62ï¼…çš„æ¦‚ç‡é™é›¨",
        "å¤§ğŸŒï¼Œä¸€æ¡å¤§ğŸŒï¼Œå˜¿ï¼Œä½ çš„æ„Ÿè§‰çœŸçš„å¾ˆå¥‡å¦™  [lbreak]",
        "I like eating ğŸ",
        """
# ä½ å¥½ï¼Œä¸–ç•Œ
```js
console.log('1')
```
**åŠ ç²—**

*ä¸€æ¡æ–‡æœ¬*
        """,
        """
åœ¨æ²™æ¼ ã€å²©çŸ³ã€é›ªåœ°ä¸Šè¡Œèµ°äº†å¾ˆé•¿çš„æ—¶é—´ä»¥åï¼Œå°ç‹å­ç»ˆäºå‘ç°äº†ä¸€æ¡å¤§è·¯ã€‚æ‰€æœ‰çš„å¤§è·¯éƒ½æ˜¯é€šå¾€äººä½çš„åœ°æ–¹çš„ã€‚
â€œä½ ä»¬å¥½ã€‚â€å°ç‹å­è¯´ã€‚
è¿™æ˜¯ä¸€ä¸ªç«ç‘°ç››å¼€çš„èŠ±å›­ã€‚
â€œä½ å¥½ã€‚â€ç«ç‘°èŠ±è¯´é“ã€‚
å°ç‹å­ç…ç€è¿™äº›èŠ±ï¼Œå®ƒä»¬å…¨éƒ½å’Œä»–çš„é‚£æœµèŠ±ä¸€æ ·ã€‚
â€œä½ ä»¬æ˜¯ä»€ä¹ˆèŠ±ï¼Ÿâ€å°ç‹å­æƒŠå¥‡åœ°é—®ã€‚
â€œæˆ‘ä»¬æ˜¯ç«ç‘°èŠ±ã€‚â€èŠ±å„¿ä»¬è¯´é“ã€‚
â€œå•Šï¼â€å°ç‹å­è¯´â€¦â€¦ã€‚
        """,
        """
State-of-the-art Machine Learning for PyTorch, TensorFlow, and JAX.

ğŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch. These models support common tasks in different modalities, such as:

ğŸ“ Natural Language Processing: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.
ğŸ–¼ï¸ Computer Vision: image classification, object detection, and segmentation.
ğŸ—£ï¸ Audio: automatic speech recognition and audio classification.
ğŸ™ Multimodal: table question answering, optical character recognition, information extraction from scanned documents, video classification, and visual question answering.
        """,
        """
120ç±³
æœ‰12%çš„æ¦‚ç‡ä¼šä¸‹é›¨
åŸƒéš†Â·é©¬æ–¯å…‹
""",
    ]

    for i, test_case in enumerate(test_cases):
        print(f"case {i}:\n", {"x": ChatTtsTN.normalize(test_case)})
