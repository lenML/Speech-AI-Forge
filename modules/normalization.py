from modules.utils.zh_normalization.text_normlization import *
import emojiswitch
from modules.utils.markdown import markdown_to_text

post_normalize_pipeline = []
pre_normalize_pipeline = []


def post_normalize():
    def decorator(func):
        post_normalize_pipeline.append(func)
        return func

    return decorator


def pre_normalize():
    def decorator(func):
        pre_normalize_pipeline.append(func)
        return func

    return decorator


def apply_pre_normalize(text):
    for func in pre_normalize_pipeline:
        text = func(text)
    return text


def apply_post_normalize(text):
    for func in post_normalize_pipeline:
        text = func(text)
    return text


def is_markdown(text):
    markdown_patterns = [
        r"(^|\s)#[^#]",  # æ ‡é¢˜
        r"\*\*.*?\*\*",  # åŠ ç²—
        r"\*.*?\*",  # æ–œä½“
        r"!\[.*?\]\(.*?\)",  # å›¾ç‰‡
        r"\[.*?\]\(.*?\)",  # é“¾æ¥
        r"`[^`]+`",  # è¡Œå†…ä»£ç 
        r"```[\s\S]*?```",  # ä»£ç å—
        r"(^|\s)\* ",  # æ— åºåˆ—è¡¨
        r"(^|\s)\d+\. ",  # æœ‰åºåˆ—è¡¨
        r"(^|\s)> ",  # å¼•ç”¨
        r"(^|\s)---",  # åˆ†éš”çº¿
    ]

    for pattern in markdown_patterns:
        if re.search(pattern, text, re.MULTILINE):
            return True

    return False


character_map = {
    "ï¼š": "ï¼Œ",
    "ï¼›": "ï¼Œ",
    "ï¼": "ã€‚",
    "ï¼ˆ": "ï¼Œ",
    "ï¼‰": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€‘": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€Œ": "ï¼Œ",
    "ã€": "ï¼Œ",
    "ã€Š": "ï¼Œ",
    "ã€‹": "ï¼Œ",
    "ï¼": "ï¼Œ",
    "â€˜": " ",
    "â€œ": " ",
    "â€™": " ",
    "â€": " ",
    ":": ",",
    ";": ",",
    "!": ".",
    "(": ",",
    ")": ",",
    # '[': ',',
    # ']': ',',
    ">": ",",
    "<": ",",
    "-": ",",
}

character_to_word = {
    " & ": " and ",
}


@post_normalize()
def apply_character_to_word(text):
    for k, v in character_to_word.items():
        text = text.replace(k, v)
    return text


@post_normalize()
def apply_character_map(text):
    translation_table = str.maketrans(character_map)
    return text.translate(translation_table)


@post_normalize()
def apply_emoji_map(text):
    return emojiswitch.demojize(text, delimiters=("", ""), lang="zh")


@pre_normalize()
def apply_markdown_to_text(text):
    if is_markdown(text):
        text = markdown_to_text(text)
    return text


@post_normalize()
def insert_spaces_between_uppercase(s):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åœ¨æ¯ä¸ªç›¸é‚»çš„å¤§å†™å­—æ¯ä¹‹é—´æ’å…¥ç©ºæ ¼
    return re.sub(
        r"(?<=[A-Z])(?=[A-Z])|(?<=[a-z])(?=[A-Z])|(?<=[\u4e00-\u9fa5])(?=[A-Z])|(?<=[A-Z])(?=[\u4e00-\u9fa5])",
        " ",
        s,
    )


def ensure_suffix(a: str, b: str, c: str):
    a = a.strip()
    if not a.endswith(b):
        a += c
    return a


email_domain_map = {
    "outlook.com": "Out look",
    "hotmail.com": "Hot mail",
    "yahoo.com": "é›…è™",
}


# æ‰¾åˆ°æ‰€æœ‰ email å¹¶å°† name åˆ†å‰²ä¸ºå•ä¸ªå­—æ¯ï¼Œ@æ›¿æ¢ä¸º at ï¼Œ. æ›¿æ¢ä¸º dotï¼Œå¸¸è§åŸŸåæ›¿æ¢ä¸ºå•è¯
#
# ä¾‹å¦‚:
# zhzluke96@outlook.com => z h z l u k e 9 6 at out look dot com
def email_detect(text):
    email_pattern = re.compile(r"([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})")

    def replace(match):
        email = match.group(1)
        name, domain = email.split("@")
        name = " ".join(name)
        if domain in email_domain_map:
            domain = email_domain_map[domain]
        domain = domain.replace(".", " dot ")
        return f"{name} at {domain}"

    return email_pattern.sub(replace, text)


def sentence_normalize(sentence_text: str):
    # https://github.com/PaddlePaddle/PaddleSpeech/tree/develop/paddlespeech/t2s/frontend/zh_normalization
    tx = TextNormalizer()

    # åŒ¹é… \[.+?\] çš„éƒ¨åˆ†
    pattern = re.compile(r"(\[.+?\])|([^[]+)")

    def normalize_part(part):
        sentences = tx.normalize(part)
        dest_text = ""
        for sentence in sentences:
            dest_text += sentence
        return dest_text

    def replace(match):
        if match.group(1):
            return f" {match.group(1)} "
        else:
            return normalize_part(match.group(2))

    result = pattern.sub(replace, sentence_text)

    # NOTE: åŠ äº†ä¼šæœ‰æ‚éŸ³...
    # if is_end:
    # åŠ è¿™ä¸ªæ˜¯ä¸ºäº†é˜²æ­¢åå­—
    # result = ensure_suffix(result, "[uv_break]", "ã€‚ã€‚ã€‚[uv_break]ã€‚ã€‚ã€‚")

    return result


def text_normalize(text, is_end=False):
    text = apply_pre_normalize(text)
    lines = text.split("\n")
    lines = [line.strip() for line in lines]
    lines = [line for line in lines if line]
    lines = [sentence_normalize(line) for line in lines]
    content = "\n".join(lines)
    content = apply_post_normalize(content)
    return content


if __name__ == "__main__":
    test_cases = [
        "ChatTTSæ˜¯ä¸“é—¨ä¸ºå¯¹è¯åœºæ™¯è®¾è®¡çš„æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹ï¼Œä¾‹å¦‚LLMåŠ©æ‰‹å¯¹è¯ä»»åŠ¡ã€‚å®ƒæ”¯æŒè‹±æ–‡å’Œä¸­æ–‡ä¸¤ç§è¯­è¨€ã€‚æœ€å¤§çš„æ¨¡å‹ä½¿ç”¨äº†10ä¸‡å°æ—¶ä»¥ä¸Šçš„ä¸­è‹±æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒã€‚åœ¨HuggingFaceä¸­å¼€æºçš„ç‰ˆæœ¬ä¸º4ä¸‡å°æ—¶è®­ç»ƒä¸”æœªSFTçš„ç‰ˆæœ¬.",
        " [oral_9] [laugh_0] [break_0] ç”µ [speed_0] å½± [speed_0] ä¸­ æ¢æœä¼Ÿ [speed_9] æ‰®æ¼”çš„é™ˆæ°¸ä»çš„ç¼–å·27149",
        " æ˜å¤©æœ‰62ï¼…çš„æ¦‚ç‡é™é›¨",
        "å¤§ğŸŒï¼Œä¸€æ¡å¤§ğŸŒï¼Œå˜¿ï¼Œä½ çš„æ„Ÿè§‰çœŸçš„å¾ˆå¥‡å¦™  [lbreak]",
        """
# ä½ å¥½ï¼Œä¸–ç•Œ
```js
console.log('1')
```
**åŠ ç²—**

*ä¸€æ¡æ–‡æœ¬*
        """,
    ]

    for i, test_case in enumerate(test_cases):
        print(f"case {i}:\n", {"x": text_normalize(test_case, is_end=True)})
