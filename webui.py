import gradio as gr
import io

import torch

from modules.ssml import parse_ssml, synthesize_segments, combine_audio_segments
from modules.generate_audio import generate_audio

from modules.speaker import speaker_mgr
from modules.data import styles_mgr

from modules.api.utils import calc_spk_style

from modules.utils.normalization import text_normalize
from modules import refiner

torch._dynamo.config.cache_size_limit = 64
torch._dynamo.config.suppress_errors = True
torch.set_float32_matmul_precision("high")


def get_speakers():
    return speaker_mgr.list_speakers()


def get_styles():
    return styles_mgr.list_items()


@torch.inference_mode()
def synthesize_ssml(ssml: str):
    segments = parse_ssml(ssml)

    audio_segments = synthesize_segments(segments)
    combined_audio = combine_audio_segments(audio_segments)

    buffer = io.BytesIO()
    combined_audio.export(buffer, format="wav")

    return buffer.read()


@torch.inference_mode()
def tts_generate(
    text,
    temperature,
    top_p,
    top_k,
    spk,
    infer_seed,
    use_decoder,
    prompt1,
    prompt2,
    prefix,
    style,
):
    params = calc_spk_style(spk=spk, style=style)

    spk = params.get("spk", spk)
    infer_seed = infer_seed or params.get("seed", infer_seed)
    temperature = temperature or params.get("temperature", temperature)
    prefix = prefix or params.get("prefix", prefix)
    prompt1 = prompt1 or params.get("prompt1", "")
    prompt2 = prompt2 or params.get("prompt2", "")

    sample_rate, audio_data = generate_audio(
        text=text_normalize(text),
        temperature=temperature,
        top_P=top_p,
        top_K=top_k,
        spk=spk,
        infer_seed=infer_seed,
        use_decoder=use_decoder,
        prompt1=prompt1,
        prompt2=prompt2,
        prefix=prefix,
    )

    return sample_rate, audio_data


@torch.inference_mode()
def refine_text(text: str):
    return refiner.refine_text(text)


def read_local_readme():
    with open("README.md", "r", encoding="utf-8") as file:
        return file.read()


# æ¼”ç¤ºç¤ºä¾‹æ–‡æœ¬
sample_texts = [
    {
        "text": "å¤©æ°”é¢„æŠ¥æ˜¾ç¤ºï¼Œä»Šå¤©ä¼šæœ‰å°é›¨ï¼Œè¯·å¤§å®¶å‡ºé—¨æ—¶è®°å¾—å¸¦ä¼ã€‚é™æ¸©çš„å¤©æ°”ä¹Ÿæé†’æˆ‘ä»¬è¦é€‚æ—¶æ·»è¡£ä¿æš–ã€‚",
    },
    {
        "text": "å…¬å¸çš„å¹´åº¦æ€»ç»“ä¼šè®®å°†åœ¨ä¸‹å‘¨ä¸‰ä¸¾è¡Œï¼Œè¯·å„éƒ¨é—¨æå‰å‡†å¤‡å¥½ç›¸å…³ææ–™ï¼Œç¡®ä¿ä¼šè®®é¡ºåˆ©è¿›è¡Œã€‚",
    },
    {
        "text": "ä»Šå¤©çš„åˆé¤èœå•åŒ…æ‹¬çƒ¤é¸¡ã€æ²™æ‹‰å’Œè”¬èœæ±¤ï¼Œå¤§å®¶å¯ä»¥æ ¹æ®è‡ªå·±çš„å£å‘³é€‰æ‹©é€‚åˆçš„èœå“ã€‚",
    },
    {
        "text": "è¯·æ³¨æ„ï¼Œç”µæ¢¯å°†åœ¨ä¸‹åˆä¸¤ç‚¹è¿›è¡Œä¾‹è¡Œç»´æŠ¤ï¼Œé¢„è®¡éœ€è¦ä¸€ä¸ªå°æ—¶çš„æ—¶é—´ï¼Œè¯·å¤§å®¶åœ¨æ­¤æœŸé—´ä½¿ç”¨æ¥¼æ¢¯ã€‚",
    },
    {
        "text": "å›¾ä¹¦é¦†æ–°åˆ°äº†ä¸€æ‰¹ä¹¦ç±ï¼Œæ¶µç›–äº†æ–‡å­¦ã€ç§‘å­¦å’Œå†å²ç­‰å¤šä¸ªé¢†åŸŸï¼Œæ¬¢è¿å¤§å®¶å‰æ¥å€Ÿé˜…ã€‚",
    },
    {
        "text": "ç”µå½±ä¸­æ¢æœä¼Ÿæ‰®æ¼”çš„é™ˆæ°¸ä»çš„ç¼–å·27149",
    },
    {
        "text": "è¿™å—é»„é‡‘é‡è¾¾324.75å…‹",
    },
    {
        "text": "æˆ‘ä»¬ç­çš„æœ€é«˜æ€»åˆ†ä¸º583åˆ†",
    },
    {
        "text": "12~23",
    },
    {
        "text": "-1.5~2",
    },
    {
        "text": "å¥¹å‡ºç”Ÿäº86å¹´8æœˆ18æ—¥ï¼Œå¥¹å¼Ÿå¼Ÿå‡ºç”Ÿäº1995å¹´3æœˆ1æ—¥",
    },
    {
        "text": "ç­‰ä¼šè¯·åœ¨12:05è¯·é€šçŸ¥æˆ‘",
    },
    {
        "text": "ä»Šå¤©çš„æœ€ä½æ°”æ¸©è¾¾åˆ°-10Â°C",
    },
    {
        "text": "ç°åœºæœ‰7/12çš„è§‚ä¼—æŠ•å‡ºäº†èµæˆç¥¨",
    },
    {
        "text": "æ˜å¤©æœ‰62ï¼…çš„æ¦‚ç‡é™é›¨",
    },
    {
        "text": "éšä¾¿æ¥å‡ ä¸ªä»·æ ¼12å—5ï¼Œ34.5å…ƒï¼Œ20.1ä¸‡",
    },
    {
        "text": "è¿™æ˜¯å›ºè¯0421-33441122",
    },
    {
        "text": "è¿™æ˜¯æ‰‹æœº+86 18544139121",
    },
]

ssml_example1 = """
<speak version="0.1">
    <voice spk="Bob" style="narration-relaxed">
        ä¸‹é¢æ˜¯ä¸€ä¸ª ChatTTS ç”¨äºåˆæˆå¤šè§’è‰²å¤šæƒ…æ„Ÿçš„æœ‰å£°ä¹¦ç¤ºä¾‹
    </voice>
    <voice spk="Bob" style="narration-relaxed">
        é»›ç‰å†·ç¬‘é“ï¼š
    </voice>
    <voice spk="female2" style="angry">
        æˆ‘è¯´å‘¢ [uv_break] ï¼Œäºäº†ç»Šä½ï¼Œä¸ç„¶ï¼Œæ—©å°±é£èµ·æ¥äº†ã€‚
    </voice>
    <voice spk="Bob" style="narration-relaxed">
        å®ç‰é“ï¼š
    </voice>
    <voice spk="Alice" style="unfriendly">
        â€œåªè®¸å’Œä½ ç© [uv_break] ï¼Œæ›¿ä½ è§£é—·ã€‚ä¸è¿‡å¶ç„¶åˆ°ä»–é‚£é‡Œï¼Œå°±è¯´è¿™äº›é—²è¯ã€‚â€
    </voice>
    <voice spk="female2" style="angry">
        â€œå¥½æ²¡æ„æ€çš„è¯ï¼[uv_break] å»ä¸å»ï¼Œå…³æˆ‘ä»€ä¹ˆäº‹å„¿ï¼Ÿ åˆæ²¡å«ä½ æ›¿æˆ‘è§£é—·å„¿ [uv_break]ï¼Œè¿˜è®¸ä½ ä¸ç†æˆ‘å‘¢â€
    </voice>
    <voice spk="Bob" style="narration-relaxed">
        è¯´ç€ï¼Œä¾¿èµŒæ°”å›æˆ¿å»äº†ã€‚
    </voice>
</speak>
"""
ssml_example2 = """
<speak version="0.1">
    <voice spk="Bob" style="narration-relaxed">
        ä½¿ç”¨ prosody æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„è¯­é€Ÿè¯­è°ƒå’ŒéŸ³é‡ï¼Œç¤ºä¾‹å¦‚ä¸‹

        <prosody>
            æ— ä»»ä½•é™åˆ¶å°†ä¼šç»§æ‰¿çˆ¶çº§voiceé…ç½®è¿›è¡Œç”Ÿæˆ
        </prosody>
        <prosody rate="1.5">
            è®¾ç½® rate å¤§äº1è¡¨ç¤ºåŠ é€Ÿï¼Œå°äº1ä¸ºå‡é€Ÿ
        </prosody>
        <prosody pitch="6">
            è®¾ç½® pitch è°ƒæ•´éŸ³è°ƒï¼Œè®¾ç½®ä¸º6è¡¨ç¤ºæé«˜6ä¸ªåŠéŸ³
        </prosody>
        <prosody volume="2">
            è®¾ç½® volume è°ƒæ•´éŸ³é‡ï¼Œè®¾ç½®ä¸º2è¡¨ç¤ºæé«˜2ä¸ªåˆ†è´
        </prosody>

        åœ¨ voice ä¸­æ— prosodyåŒ…è£¹çš„æ–‡æœ¬å³ä¸ºé»˜è®¤ç”ŸæˆçŠ¶æ€ä¸‹çš„è¯­éŸ³
    </voice>
</speak>
"""
ssml_example3 = """
<speak version="0.1">
    <voice spk="Bob" style="narration-relaxed">
        ä½¿ç”¨ break æ ‡ç­¾å°†ä¼šç®€å•çš„
        
        <break time="500" />

        æ’å…¥ä¸€æ®µç©ºç™½åˆ°ç”Ÿæˆç»“æœä¸­ 
    </voice>
</speak>
"""

ssml_example4 = """
<speak version="0.1">
    <voice spk="Bob" style="excited">
        temperature for sampling (may be overridden by style or speaker)
        <break time="500" />
        æ¸©åº¦å€¼ç”¨äºé‡‡æ ·ï¼Œè¿™ä¸ªå€¼æœ‰å¯èƒ½è¢« style æˆ–è€… speaker è¦†ç›– 
        <break time="500" />
        temperature for sampling ï¼Œè¿™ä¸ªå€¼æœ‰å¯èƒ½è¢« style æˆ–è€… speaker è¦†ç›– 
        <break time="500" />
        æ¸©åº¦å€¼ç”¨äºé‡‡æ ·ï¼Œ(may be overridden by style or speaker)
    </voice>
</speak>
"""

default_ssml = """
<speak version="0.1">
  <voice spk="Bob" seed="-1" style="narration-relaxed">
    è¿™é‡Œæ˜¯ä¸€ä¸ªç®€å•çš„ SSML ç¤ºä¾‹ã€‚ 
  </voice>
</speak>
"""


def create_interface():
    speakers = get_speakers()
    speaker_names = ["*random"] + [speaker.name for speaker in speakers]

    styles = ["*auto"] + [s.get("name") for s in get_styles()]

    js_func = """
    function refresh() {
        const url = new URL(window.location);

        if (url.searchParams.get('__theme') !== 'dark') {
            url.searchParams.set('__theme', 'dark');
            window.location.href = url.href;
        }
    }
    """

    with gr.Blocks(js=js_func) as demo:
        with gr.Tabs():
            with gr.TabItem("TTS"):
                with gr.Row():
                    with gr.Column(scale=1):
                        temperature_input = gr.Slider(
                            0.0, 1.0, value=0.3, label="Temperature"
                        )
                        top_p_input = gr.Slider(0.0, 1.0, value=0.7, label="Top P")
                        top_k_input = gr.Slider(1, 50, value=20, label="Top K")

                        with gr.Row():
                            spk_input_text = gr.Textbox(
                                label="Speaker (Text or Seed)", value="female2"
                            )
                            spk_input_dropdown = gr.Dropdown(
                                choices=speaker_names,
                                label="Choose Speaker",
                                interactive=True,
                                value="female2",
                            )
                            spk_input_dropdown.change(
                                fn=lambda x: x.startswith("*") and "-1" or x,
                                inputs=[spk_input_dropdown],
                                outputs=[spk_input_text],
                            )

                        with gr.Row():
                            style_input_text = gr.Textbox(
                                label="Style (Text or Seed)", value="-1"
                            )
                            style_input_dropdown = gr.Dropdown(
                                choices=styles,
                                label="Choose Style",
                                interactive=True,
                                value="*auto",
                            )
                            style_input_dropdown.change(
                                fn=lambda x: x.startswith("*") and "-1" or x,
                                inputs=[style_input_dropdown],
                                outputs=[style_input_text],
                            )
                        infer_seed_input = gr.Number(value=-1, label="Inference Seed")
                        use_decoder_input = gr.Checkbox(value=True, label="Use Decoder")
                        prompt1_input = gr.Textbox(label="Prompt 1")
                        prompt2_input = gr.Textbox(label="Prompt 2")
                        prefix_input = gr.Textbox(label="Prefix")
                    with gr.Column(scale=3):
                        text_input = gr.Textbox(
                            label="Text to Speech",
                            lines=10,
                            placeholder="è¾“å…¥æ–‡æœ¬æˆ–é€‰æ‹©ç¤ºä¾‹",
                        )
                        sample_dropdown = gr.Dropdown(
                            choices=[sample["text"] for sample in sample_texts],
                            label="é€‰æ‹©ç¤ºä¾‹",
                            value=None,
                            interactive=True,
                        )
                        sample_dropdown.change(
                            fn=lambda x: x,
                            inputs=[sample_dropdown],
                            outputs=[text_input],
                        )
                        with gr.Row():
                            refine_button = gr.Button("âœï¸Refine Text")
                            tts_button = gr.Button("ğŸ”ŠGenerate Audio")

                        tts_output = gr.Audio(label="Generated Audio")

                refine_button.click(
                    refine_text,
                    inputs=[text_input],
                    outputs=[text_input],
                )

                tts_button.click(
                    tts_generate,
                    inputs=[
                        text_input,
                        temperature_input,
                        top_p_input,
                        top_k_input,
                        spk_input_text,
                        infer_seed_input,
                        use_decoder_input,
                        prompt1_input,
                        prompt2_input,
                        prefix_input,
                        style_input_text,
                    ],
                    outputs=tts_output,
                )

            with gr.TabItem("SSML"):
                ssml_input = gr.Textbox(
                    label="SSML Input",
                    lines=10,
                    value=default_ssml,
                )
                ssml_button = gr.Button("ğŸ”ŠSynthesize SSML")
                ssml_output = gr.Audio(label="Generated Audio")

                ssml_button.click(
                    synthesize_ssml,
                    inputs=[ssml_input],
                    outputs=ssml_output,
                )

                examples = [
                    ssml_example1,
                    ssml_example2,
                    ssml_example3,
                    ssml_example4,
                ]

                gr.Examples(
                    examples=examples,
                    inputs=[ssml_input],
                )

            with gr.TabItem("README"):
                readme_content = read_local_readme()
                gr.Markdown(readme_content)

        gr.Markdown(
            "æ­¤é¡¹ç›®åŸºäº [ChatTTS-Forge](https://github.com/lenML/ChatTTS-Forge) "
        )

    return demo


if __name__ == "__main__":
    demo = create_interface()
    demo.queue().launch(share=False)
